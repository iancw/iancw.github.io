---
layout: post
status: publish
published: true
title: Practical Object Oriented Design in Ruby
author:
  display_name: ian
  login: ian
  email: icwill@gmail.com
  url: http://iancwill.com/blog
author_login: ian
author_email: icwill@gmail.com
author_url: http://iancwill.com/blog
wordpress_id: 162
wordpress_url: http://iancwill.com/blog/?p=162
date: '2014-05-01 23:38:10 -0600'
date_gmt: '2014-05-02 03:38:10 -0600'
categories:
- Uncategorized
tags: []
comments: []
---
<p>I just finished Sandi Metz's book Practical Object-Oriented Design in Ruby.  It is a worthwhile read.  Programming books can use a lot of words for a small handful of takeaways.  POODR had a  high takeaway-to-words ratio.</p>
<p>First a little background on where I'm coming from.  I really like the design of the Ruby language.  I enjoy the flowing syntax.  I'm fine with multiple ways to accomplish the same thing.  It's very natural (as in natural languages).  I also enjoy the minimalism it allows--no empty parentheses, return statements optional!  My daily language is Java, and has been for my entire career.  My Java work is in a large legacy codebase that has been through some rough times and is starting to develop a few islands of sane design.  Much of the sanity is thanks to the concept of dependency injection, which a few likeminded coworkers and I gleaned from the Google testability blog.  I don't like Java's boilerplate-heavy, ceremony-laden syntax.  But I found myself thinking how many of the problems created by duck-typing and dynamic types (namely the "how do I make sure classes continue to properly implement an interface as it changes?" and the argument ordering problems) are pretty effectively solved by Java Interfaces and static typing.  Toward the end of the book, it seemed Sandi devoted many pages to describing how to make duck-types safe for future changes, and the tradeoff seems to come down to safety through unit tests rather than safety through compiler checks.  If compiler checks accomplish the same thing, they do so with less work (no unit tests required! ...).  </p>
<p>I like how Sandi spends time trying to shape how we think about objects.  Early on she emphasizes object interactions as the most important aspect of OO design.  This deserves emphasis because the interactions between objects are largely invisible with our current tools.  Their most effective visualization is as lines between large, attention-dominating boxes in UML diagrams.  But I believe she is correct in assessing the arrangement and quantity of these lines between the "boxes" as much more important than the contents of the boxes themselves.  Of course the contents of the boxes are very directly related to how they're interconnected.</p>
<p>That leads to another idea that Sandi spends time with:  single-responsiblity classes.  The call graph for an application with many small classes will look very different from an application with a few large, complex objects.  Perhaps initially this is easier to comprehend for the procedural programmer (where many of us begin).  If allowed to grow into an application with many complex objects, the complexity of their relationships expands greatly.  Single-responsiblity classes encourage orthogonality.  If each class really does only one thing, it should readily apply in any part of the application where that one thing is necessary.  Conversely, the more a single class does, the less likely it is to fit perfectly into a similar situation.  (I wonder if there are similar arguments to be made when designing an application -- feature "rich" versus simple and focused)</p>
<p>The idea of delaying design decisions intelligently is also quite compelling.  It's a line that must be walked with care.  It may be tempting to embrace more complexity, thinking it preserves options for the future.  But in fact, increased complexity can lock you in to the selected complex approach, making it more difficult to change.  Instead, delaying design decisions means avoiding complexity until absolutely necessary.  Don't build scaffolding toward future requirements.  Just keep your code simple and orthogonal.  Orthogonality is achieved by restricting classes to a single-responsibity.</p>
<p>Sandi's admonition to write exemplary code is also quite perceptive.  Like dirty dishes, unclean code invites others to leave their code messes for later.</p>
<p>Writing small methods is such good advice.  It's so simple, seemingly obvious, but so helpful.  Even though I'm a huge proponent, I still find myself regularly realizing that I've packed too much complexity into one method.  It's feels so nice to pull that ternary statement out of chain of logic and replace it with a clearly named method call (to a tiny method that's trivial to grasp).    I really like the idea that if a line or two are complex enough to require a comment, they're probably worth pulling into an appropriately named method.  That's already helped improve my code.</p>
<p>However, I think I take exception to only accessing a member variable except through its getter.   It's one thing in Ruby, where parentheses are optional and attr_accessor does all the work for you.  But in Java, where it's "get" this "set" that?  I'd rather just write "it" instead of "getIt()", "setIt()" all over.  (Plus eclipse turns it blue and shows you its contents on mouse-over when debugging.)</p>
<p>Sandi categorizes dependencies into four types:<br />
 1. Knowing on the name of another class (e.g. by calling new ClassName)<br />
 2. Knowing on the name of a message sent to a class<br />
 3. Knowing the arguments a message takes<br />
 4. Knowing the order of the arguments a message expects</p>
<p>She recommends removing type 1 dependencies through duck typing, limiting class scope, and dependency injection (avoiding calls to new).  That's well and good.  Type 2 dependencies are necessary when classes collaborate, and keeping class responsibilities small should help keep those sane.  I'm not sure I agree with her solution to removing type 4 dependencies.  She recommends passing an argument hash.  In ruby this is pretty slick, with symbols instead of strings, and its all dynamically typed anyway you don't loose too much.  However, the all-encompassing hash parameter can quickly get out of hand.  NASA's WorldWind library uses something like this in its AVKey class.  These AVKeys come from who knows where--XML configuration files, side effects from various other methods, gamma rays, I never know.  And who knows which keys are needed!?  Reading the code immediately surrounding the method call doesn't tell you anything.  You have to follow it ten levels up or down, or just run the code and inspect what values are set (and then figure out how all that happened) then see what blows up because it was expecting a key that wasn't set!  Hideous.  It's flexible, sure.  It's great if you know the code backwards and forwards.  It's horrible for reading, learning, and extending.  WorldWind's AVKey is a strong example.  I don't think Sandi is proposing that extreme use.  However, without care, in large applications, I think passing hashes can quickly get out of hand.  You really, really need good unit tests in those cases.  You're trading off compiler-based error checking for unit-test based error checking.  You do gain a lot of flexibility.  Maybe in ruby, where passing the wrong type of parameter won't be caught until runtime, it's a net gain.  But in Java you sacrifice that comforting safety blanked of compile-time error checking.  She tries to argue that I need to let go of that safety blanked and embrace freedom.  But isn't it always better to find bugs earlier rather than later?</p>
<p>But maybe it's a useful technique to use occasionally in Java.  One example might be constructors with many arguments.  The symptom is likely an indication that the class does too much.  But occasionally there are communication hubs that just need be connected to many other classes for valid reasons. Even with good type checking it can be painful to work with.  Plus, subclasses can mix up orderings and get things really whacky.  This may be a good time to use a hash.  Perhaps until the class can be properly decomposed.</p>
<p>Sandi recommends sequence diagrams for visualizing interfaces.  She admonishes us not to re-invent the wheel, since lots of thought went into UML.  While I regularly diagram out sequences of calls, I typically use my own notation with circles representing objects and arrows representing messages.  My style is more space-friendly (denser information), but lacks a clear sequence when calls return to the original object and go elsewhere.  My biggest problem with the traditional UML sequence diagram is that they are painful to create in an exploratory fashion.  The typical use case for me is when I discover a thicket of code where there's more indirection than I expect.  I start with a class at the outer fringe, and just keep growing the graph until I understand where everything is going.  Perhaps if our system was tame, traditional UML sequence diagrams would work well.  But in places, our system can have so much indirection that traditional UML sequence diagrams quickly fill all available horizontal space.  My diagram, which I'll refer to as a call graph diagram is like a typical directed graph drawing.  It allows the calls to expand in two dimensions, which lets you accommodate over-indulgent indirection.  Usually code that requires diagraming has an excessive number of calls with too much indirection to too many classes.  Thus for trying to understand messy code, I think the call graph is preferable.</p>
<p>My typical "call graph" diagram style<br />
<a href="http:&#47;&#47;iancwill.com&#47;blog&#47;wp-content&#47;uploads&#47;2014&#47;04&#47;sequence-diagrams1.png"><img src="http:&#47;&#47;iancwill.com&#47;blog&#47;wp-content&#47;uploads&#47;2014&#47;04&#47;sequence-diagrams1-300x185.png" alt="sequence-diagrams1" width="400" class="alignnone size-medium wp-image-168" &#47;><&#47;a></p>
<p>Traditional UML sequence diagram<br />
<a href="http:&#47;&#47;iancwill.com&#47;blog&#47;wp-content&#47;uploads&#47;2014&#47;04&#47;sequence-diagrams2.png"><img src="http:&#47;&#47;iancwill.com&#47;blog&#47;wp-content&#47;uploads&#47;2014&#47;04&#47;sequence-diagrams2-300x154.png" alt="sequence-diagrams2" width="400" class="alignnone size-medium wp-image-167" &#47;><&#47;a> </p>
<p>In this case, the sequence diagram probably packs more useful information into roughly the same space.  However, the call graph diagram scales better and requires less care when drawing.</p>
